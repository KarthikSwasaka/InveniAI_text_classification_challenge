This assesment consist of 
●	Split the dataset into training and test sets as appropriate.
●	Performing exploratory data analysis on the data.
●	Building a text classification model based on the dataset
●	Monitoring relevant evaluation metrics while training the model
●	Presenting any interesting or important findings from the exploratory data analysis.
●	Saving the trained NLP model and make it available through an API.
●	Dockerizing the API.
●	Hosting a local RabbitMQ message queue server and sending data for inference through the message queue.
●	Creating a RabbitMQ Consumer that consumes data from the queue and makes an API call for model inference.
●	Saving the inference results along with the text on which model inference was made in a Postgres Database (which can be locally hosted on my machine).
